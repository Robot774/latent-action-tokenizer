#!/usr/bin/env python3
"""
æµ‹è¯•æ‰‹éƒ¨å…³é”®ç‚¹å¯è§†åŒ–åŠŸèƒ½
Test Hand Keypoint Visualization
"""

import pyrootutils
pyrootutils.setup_root(__file__, indicator='.project-root', pythonpath=True, dotenv=True)

import os
import sys
import numpy as np
import torch
from pathlib import Path

# æ·»åŠ å¯è§†åŒ–æ¨¡å—è·¯å¾„
sys.path.append('Moto_copy/hrdt')
from visualization.hand_keypoint_visualizer import HandKeypointVisualizer, visualize_egodx_sample
from datasets.pretrain.egodex_dataset import EgoDexDataset
from datasets.dataset import VLAConsumerDataset, MultiDataCollatorForVLAConsumerDataset


def test_basic_visualizer():
    """æµ‹è¯•åŸºç¡€å¯è§†åŒ–å™¨åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•1: åŸºç¡€å¯è§†åŒ–å™¨åŠŸèƒ½")
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = HandKeypointVisualizer(image_width=640, image_height=480, fps=10)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    # ç”Ÿæˆç®€å•çš„48DåŠ¨ä½œæ•°æ® (æœªå½’ä¸€åŒ–)
    test_action = np.zeros(48)
    
    # å·¦æ‰‹æ•°æ® (å‰24ç»´)
    test_action[0:3] = [0.0, 0.0, 0.5]     # å·¦æ‰‹è…•ä½ç½®
    test_action[3:9] = [1, 0, 0, 1, 0, 0]  # å·¦æ‰‹è…•æ—‹è½¬(6D)
    # å·¦æ‰‹æŒ‡å°–ä½ç½® (ç›¸å¯¹åˆ†å¸ƒ)
    test_action[9:12] = [0.1, 0.0, 0.6]    # æ‹‡æŒ‡
    test_action[12:15] = [0.0, 0.1, 0.7]   # é£ŸæŒ‡
    test_action[15:18] = [0.0, 0.0, 0.8]   # ä¸­æŒ‡
    test_action[18:21] = [0.0, -0.1, 0.7]  # æ— åæŒ‡
    test_action[21:24] = [-0.1, -0.1, 0.6] # å°æŒ‡
    
    # å³æ‰‹æ•°æ® (å24ç»´)
    test_action[24:27] = [0.0, 0.0, 0.5]   # å³æ‰‹è…•ä½ç½®
    test_action[27:33] = [1, 0, 0, 1, 0, 0] # å³æ‰‹è…•æ—‹è½¬(6D)
    # å³æ‰‹æŒ‡å°–ä½ç½®
    test_action[33:36] = [-0.1, 0.0, 0.6]  # æ‹‡æŒ‡
    test_action[36:39] = [0.0, 0.1, 0.7]   # é£ŸæŒ‡
    test_action[39:42] = [0.0, 0.0, 0.8]   # ä¸­æŒ‡
    test_action[42:45] = [0.0, -0.1, 0.7]  # æ— åæŒ‡
    test_action[45:48] = [0.1, -0.1, 0.6]  # å°æŒ‡
    
    # åˆ›å»ºæµ‹è¯•ç›¸æœºå‚æ•°
    camera_intrinsics = np.array([
        [500.0, 0.0, 320.0],
        [0.0, 500.0, 240.0],
        [0.0, 0.0, 1.0]
    ])
    
    camera_extrinsics = np.eye(4)  # å•ä½çŸ©é˜µè¡¨ç¤ºç›¸æœºåœ¨ä¸–ç•Œåæ ‡åŸç‚¹
    
    # æµ‹è¯•48Dè§£æ
    parsed = visualizer.parse_48d_action(test_action)
    print(f"   âœ… 48Dè§£ææˆåŠŸ:")
    print(f"      - å·¦æ‰‹è…•ä½ç½®: {parsed['left_wrist_pos']}")
    print(f"      - å·¦æ‰‹æŒ‡å°–æ•°é‡: {parsed['left_fingertips'].shape}")
    print(f"      - å³æ‰‹è…•ä½ç½®: {parsed['right_wrist_pos']}")
    print(f"      - å³æ‰‹æŒ‡å°–æ•°é‡: {parsed['right_fingertips'].shape}")
    
    # æµ‹è¯•3Dåˆ°2DæŠ•å½±
    test_points_3d = np.array([[0, 0, 1], [0.1, 0, 1], [-0.1, 0, 1]])
    points_2d = visualizer.project_3d_to_2d(test_points_3d, camera_extrinsics, camera_intrinsics)
    print(f"   âœ… 3Dåˆ°2DæŠ•å½±æˆåŠŸ: {test_points_3d.shape} -> {points_2d.shape}")
    print(f"      - æŠ•å½±ç»“æœ: {points_2d}")
    
    # æµ‹è¯•å•å¸§ç”Ÿæˆ
    frame = visualizer.create_frame_with_keypoints(test_action, camera_extrinsics, camera_intrinsics)
    print(f"   âœ… å•å¸§ç”ŸæˆæˆåŠŸ: {frame.shape}")
    
    print("âœ… æµ‹è¯•1å®Œæˆ\n")


def test_egodx_dataset_visualization():
    """æµ‹è¯•ä½¿ç”¨EgoDxæ•°æ®é›†è¿›è¡Œå¯è§†åŒ–"""
    print("ğŸ§ª æµ‹è¯•2: EgoDxæ•°æ®é›†å¯è§†åŒ–")
    
    try:
        # åˆ›å»ºEgoDxæ•°æ®é›† (åŒ…å«ç›¸æœºå‚æ•°)
        config = {
            "common": {
                "img_history_size": 1,
                "chunk_size": 10
            }
        }
        
        dataset = EgoDexDataset(
            config=config,
            upsample_rate=5,
            val=False,
            use_precomp_lang_embed=True,
            include_camera_params=True,  # å¯ç”¨ç›¸æœºå‚æ•°
            data_root="/dataset_rc_mm/share/datasets/ml-site.cdn-apple.com/egodex",
            stat_path="/root/workspace/chenby10@xiaopeng.com/Moto_copy/hrdt/datasets/pretrain/egodex_stat.json"
        )
        
        print(f"   âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ, æ ·æœ¬æ•°é‡: {len(dataset)}")
        
        # è·å–ä¸€ä¸ªæ ·æœ¬
        sample = dataset.get_item(0)
        if sample is None:
            print("   âŒ æ— æ³•è·å–æœ‰æ•ˆæ ·æœ¬")
            return
            
        print(f"   âœ… æ ·æœ¬è·å–æˆåŠŸ")
        print(f"      - æ ·æœ¬é”®: {list(sample.keys())}")
        print(f"      - åŠ¨ä½œå½¢çŠ¶: {sample['actions'].shape}")
        
        if 'current_camera_extrinsics' in sample:
            print(f"      - å½“å‰ç›¸æœºå¤–å‚: {sample['current_camera_extrinsics'].shape}")
        if 'action_camera_extrinsics' in sample:
            print(f"      - åŠ¨ä½œç›¸æœºå¤–å‚: {sample['action_camera_extrinsics'].shape}")
        if 'camera_intrinsics' in sample:
            print(f"      - ç›¸æœºå†…å‚: {sample['camera_intrinsics'].shape}")
        
        # æµ‹è¯•å¯è§†åŒ–
        output_path = "/root/workspace/chenby10@xiaopeng.com/test_hand_visualization.mp4"
        stat_path = "/root/workspace/chenby10@xiaopeng.com/Moto_copy/hrdt/datasets/pretrain/egodex_stat.json"
        
        print(f"   ğŸ¬ å¼€å§‹ç”Ÿæˆå¯è§†åŒ–è§†é¢‘...")
        visualize_egodx_sample(
            sample_data=sample,
            output_path=output_path,
            stat_path=stat_path,
            image_size=(640, 480),
            fps=10
        )
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
            print(f"   âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {output_path}")
            print(f"      - æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        else:
            print(f"   âŒ è§†é¢‘æ–‡ä»¶æœªç”Ÿæˆ: {output_path}")
            
    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("âœ… æµ‹è¯•2å®Œæˆ\n")


def test_multi_dataset_visualization():
    """æµ‹è¯•å¤šæ•°æ®é›†çš„å¯è§†åŒ–"""
    print("ğŸ§ª æµ‹è¯•3: å¤šæ•°æ®é›†å¯è§†åŒ–")
    
    try:
        # åˆ›å»ºVLAæ•°æ®é›†
        config = {
            "common": {
                "img_history_size": 1,
                "chunk_size": 10
            }
        }
        
        # æµ‹è¯•EgoDxæ•°æ®é›†
        egodx_dataset = VLAConsumerDataset(
            config=config,
            image_transform=None,  # æš‚æ—¶ä¸å¤„ç†å›¾åƒ
            num_cameras=1,
            dataset_name="egodex"
        )
        
        print(f"   âœ… EgoDx VLAæ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºcollator
        collator = MultiDataCollatorForVLAConsumerDataset(
            unified_action_dim=48,
            use_precomp_lang_embed=True
        )
        
        # è·å–æ‰¹é‡æ ·æœ¬
        samples = [egodx_dataset[0], egodx_dataset[1]]
        batch = collator(samples)
        
        print(f"   âœ… æ‰¹é‡æ•°æ®å¤„ç†æˆåŠŸ")
        print(f"      - æ‰¹é‡å¤§å°: {batch['actions'].shape[0]}")
        print(f"      - åŠ¨ä½œå½¢çŠ¶: {batch['actions'].shape}")
        
        if 'action_camera_extrinsics' in batch:
            print(f"      - ç›¸æœºå¤–å‚å½¢çŠ¶: {batch['action_camera_extrinsics'].shape}")
        if 'camera_intrinsics' in batch:
            print(f"      - ç›¸æœºå†…å‚å½¢çŠ¶: {batch['camera_intrinsics'].shape}")
        
        # å¯è§†åŒ–ç¬¬ä¸€ä¸ªæ ·æœ¬
        first_sample = {
            'actions': batch['actions'][0],
            'action_camera_extrinsics': batch['action_camera_extrinsics'][0],
            'camera_intrinsics': batch['camera_intrinsics'][0]
        }
        
        output_path = "/root/workspace/chenby10@xiaopeng.com/test_multi_visualization.mp4"
        stat_path = "/root/workspace/chenby10@xiaopeng.com/Moto_copy/hrdt/datasets/pretrain/egodex_stat.json"
        
        print(f"   ğŸ¬ å¼€å§‹ç”Ÿæˆå¤šæ•°æ®é›†å¯è§†åŒ–...")
        visualize_egodx_sample(
            sample_data=first_sample,
            output_path=output_path,
            stat_path=stat_path,
            image_size=(640, 480),
            fps=15
        )
        
        if os.path.exists(output_path):
            print(f"   âœ… å¤šæ•°æ®é›†å¯è§†åŒ–æˆåŠŸ: {output_path}")
        else:
            print(f"   âŒ å¤šæ•°æ®é›†å¯è§†åŒ–å¤±è´¥")
            
    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("âœ… æµ‹è¯•3å®Œæˆ\n")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ‰‹éƒ¨å…³é”®ç‚¹å¯è§†åŒ–æµ‹è¯•")
    print("=" * 60)
    
    # åŸºç¡€åŠŸèƒ½æµ‹è¯•
    test_basic_visualizer()
    
    # EgoDxæ•°æ®é›†æµ‹è¯•
    test_egodx_dataset_visualization()
    
    # å¤šæ•°æ®é›†æµ‹è¯•
    test_multi_dataset_visualization()
    
    print("=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    
    output_files = [
        "/root/workspace/chenby10@xiaopeng.com/test_hand_visualization.mp4",
        "/root/workspace/chenby10@xiaopeng.com/test_multi_visualization.mp4"
    ]
    
    for file_path in output_files:
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path) / (1024 * 1024)
            print(f"   âœ… {file_path} ({file_size:.2f} MB)")
        else:
            print(f"   âŒ {file_path} (æœªç”Ÿæˆ)")


if __name__ == "__main__":
    main()
