#!/usr/bin/env python3
"""
H-RDT Data Loading Test Script
Tests actual data loading and image reading functionality
"""

import pyrootutils
pyrootutils.setup_root(__file__, indicator='.project-root', pythonpath=True, dotenv=True)

import os
import sys
import yaml
import torch
import random
import numpy as np
from pathlib import Path
from torchvision import transforms
from PIL import Image
from torch.utils.data import DataLoader

from hrdt.datasets.dataset import VLAConsumerDataset, MultiDataCollatorForVLAConsumerDataset
from hrdt.datasets.multi_hdf5_vla_dataset import MultiHDF5VLADataset

def load_config(config_path):
    """Load configuration file"""
    with open(config_path, "r") as fp:
        config = yaml.safe_load(fp)
    return config

def create_simple_image_transform():
    """Create simple image transform for testing"""
    def transform_fn(image):
        if image is None:
            image = Image.new('RGB', (224, 224), (0, 0, 0))
        
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        pixel_values = transform(image)
        return {"pixel_values": pixel_values}
    
    return transform_fn

def test_egodx_data_loading():
    """Test EgoDx dataset data loading"""
    print("ğŸ¤² æµ‹è¯•EgoDxæ•°æ®åŠ è½½...")
    
    try:
        # Load base config
        base_config = {
            "common": {
                "img_history_size": 1,
                "action_chunk_size": 4,
                "num_cameras": 1,
                "state_dim": 48,
                "action_dim": 48
            }
        }
        
        image_transform = create_simple_image_transform()
        
        # Create EgoDx dataset
        egodx_dataset = VLAConsumerDataset(
            config=base_config,
            image_transform=image_transform,
            num_cameras=1,
            dataset_name="egodex",
            dataset_type="pretrain",
            image_aug=False,
            upsample_rate=3,
            val=True,
            use_precomp_lang_embed=True,
        )
        
        print(f"  âœ… EgoDxæ•°æ®é›†åˆ›å»ºæˆåŠŸ (æ€»æ ·æœ¬æ•°: {len(egodx_dataset)})")
        
        # Test loading a few samples
        print("  ğŸ” æµ‹è¯•æ ·æœ¬åŠ è½½...")
        for i in range(min(3, len(egodx_dataset))):
            try:
                sample = egodx_dataset[i]
                
                # Check images
                if "images" in sample:
                    images = sample["images"]
                    print(f"    æ ·æœ¬ {i}:")
                    if isinstance(images, dict):
                        for key, img_tensor in images.items():
                            print(f"      å›¾åƒ({key}): å½¢çŠ¶{img_tensor.shape}, èŒƒå›´[{img_tensor.min():.3f}, {img_tensor.max():.3f}]")
                    else:
                        print(f"      å›¾åƒ: å½¢çŠ¶{images.shape}, èŒƒå›´[{images.min():.3f}, {images.max():.3f}]")
                
                # Check actions
                if "actions" in sample:
                    actions = sample["actions"]
                    print(f"      åŠ¨ä½œ: å½¢çŠ¶{actions.shape}, èŒƒå›´[{actions.min():.3f}, {actions.max():.3f}]")
                
                # Check language
                if "lang_embeds" in sample:
                    lang_embeds = sample["lang_embeds"]
                    print(f"      è¯­è¨€åµŒå…¥: å½¢çŠ¶{lang_embeds.shape}")
                    
            except Exception as e:
                print(f"    âŒ æ ·æœ¬ {i} åŠ è½½å¤±è´¥: {e}")
                
        return True
        
    except Exception as e:
        print(f"  âŒ EgoDxæ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_robotwin_data_loading():
    """Test RobotWin dataset data loading"""
    print("\nğŸ¤– æµ‹è¯•RobotWinæ•°æ®åŠ è½½...")
    
    try:
        # Load base config
        base_config = {
            "common": {
                "img_history_size": 1,
                "action_chunk_size": 4,
                "num_cameras": 3,
                "state_dim": 14,
                "action_dim": 14
            }
        }
        
        image_transform = create_simple_image_transform()
        
        # Create RobotWin dataset
        robotwin_dataset = VLAConsumerDataset(
            config=base_config,
            image_transform=image_transform,
            num_cameras=3,
            dataset_name="robotwin_agilex",
            dataset_type="finetune",
            image_aug=False,
            upsample_rate=3,
            val=True,
            use_precomp_lang_embed=True,
            task_name="open_laptop",
        )
        
        print(f"  âœ… RobotWinæ•°æ®é›†åˆ›å»ºæˆåŠŸ (æ€»æ ·æœ¬æ•°: {len(robotwin_dataset)})")
        
        # Test loading a few samples
        print("  ğŸ” æµ‹è¯•æ ·æœ¬åŠ è½½...")
        for i in range(min(3, len(robotwin_dataset))):
            try:
                sample = robotwin_dataset[i]
                
                # Check images
                if "images" in sample:
                    images = sample["images"]
                    print(f"    æ ·æœ¬ {i}:")
                    if isinstance(images, dict):
                        for key, img_tensor in images.items():
                            print(f"      å›¾åƒ({key}): å½¢çŠ¶{img_tensor.shape}, èŒƒå›´[{img_tensor.min():.3f}, {img_tensor.max():.3f}]")
                    elif isinstance(images, list):
                        print(f"      å›¾åƒåˆ—è¡¨: {len(images)}ä¸ªç›¸æœº")
                        for cam_idx, img in enumerate(images):
                            if isinstance(img, dict):
                                for key, img_tensor in img.items():
                                    print(f"        ç›¸æœº{cam_idx}({key}): å½¢çŠ¶{img_tensor.shape}, èŒƒå›´[{img_tensor.min():.3f}, {img_tensor.max():.3f}]")
                            else:
                                print(f"        ç›¸æœº{cam_idx}: å½¢çŠ¶{img.shape}, èŒƒå›´[{img.min():.3f}, {img.max():.3f}]")
                    else:
                        print(f"      å›¾åƒ: å½¢çŠ¶{images.shape}, èŒƒå›´[{images.min():.3f}, {images.max():.3f}]")
                
                # Check actions
                if "actions" in sample:
                    actions = sample["actions"]
                    print(f"      åŠ¨ä½œ: å½¢çŠ¶{actions.shape}, èŒƒå›´[{actions.min():.3f}, {actions.max():.3f}]")
                
                # Check language
                if "lang_embeds" in sample:
                    lang_embeds = sample["lang_embeds"]
                    print(f"      è¯­è¨€åµŒå…¥: å½¢çŠ¶{lang_embeds.shape}")
                    
            except Exception as e:
                print(f"    âŒ æ ·æœ¬ {i} åŠ è½½å¤±è´¥: {e}")
                
        return True
        
    except Exception as e:
        print(f"  âŒ RobotWinæ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_multi_dataset_loading():
    """Test multi-dataset loading with collator"""
    print("\nğŸ”„ æµ‹è¯•å¤šæ•°æ®é›†æ··åˆåŠ è½½...")
    
    try:
        # Load base config
        base_config = {
            "common": {
                "img_history_size": 1,
                "action_chunk_size": 4,
                "num_cameras": 1,
                "state_dim": 48,
                "action_dim": 48
            }
        }
        
        image_transform = create_simple_image_transform()
        
        # Create datasets
        datasets = []
        
        # EgoDx dataset
        try:
            egodx_dataset = VLAConsumerDataset(
                config=base_config,
                image_transform=image_transform,
                num_cameras=1,
                dataset_name="egodex",
                dataset_type="pretrain",
                image_aug=False,
                upsample_rate=3,
                val=True,
                use_precomp_lang_embed=True,
            )
            datasets.append(egodx_dataset)
            print(f"  âœ… EgoDxå­æ•°æ®é›†: {len(egodx_dataset)}ä¸ªæ ·æœ¬")
        except Exception as e:
            print(f"  âš ï¸  EgoDxæ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        
        # RobotWin dataset  
        try:
            robotwin_config = base_config.copy()
            robotwin_config["common"]["action_dim"] = 14
            robotwin_config["common"]["state_dim"] = 14
            robotwin_config["common"]["num_cameras"] = 3
            
            robotwin_dataset = VLAConsumerDataset(
                config=robotwin_config,
                image_transform=image_transform,
                num_cameras=3,
                dataset_name="robotwin_agilex",
                dataset_type="finetune",
                image_aug=False,
                upsample_rate=3,
                val=True,
                use_precomp_lang_embed=True,
                task_name="open_laptop",
            )
            datasets.append(robotwin_dataset)
            print(f"  âœ… RobotWinå­æ•°æ®é›†: {len(robotwin_dataset)}ä¸ªæ ·æœ¬")
        except Exception as e:
            print(f"  âš ï¸  RobotWinæ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        
        if not datasets:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®é›†ï¼Œè·³è¿‡å¤šæ•°æ®é›†æµ‹è¯•")
            return False
        
        # Create multi-dataset
        weights = [90, 10][:len(datasets)]  # Match config weights
        multi_dataset = MultiHDF5VLADataset(datasets, weights)
        print(f"  âœ… å¤šæ•°æ®é›†åˆ›å»ºæˆåŠŸ (æƒé‡: {weights})")
        
        # Create collator and dataloader
        collator = MultiDataCollatorForVLAConsumerDataset()
        dataloader = DataLoader(
            multi_dataset,
            batch_size=4,
            num_workers=0,  # Use 0 for debugging
            collate_fn=collator,
            pin_memory=False,
            shuffle=True,
        )
        
        print("  ğŸ” æµ‹è¯•æ‰¹æ¬¡åŠ è½½...")
        for batch_idx, batch in enumerate(dataloader):
            if batch_idx >= 2:  # Only test 2 batches
                break
                
            print(f"    æ‰¹æ¬¡ {batch_idx + 1}:")
            print(f"      Actionså½¢çŠ¶: {batch['actions'].shape}")
            
            # Check dataset distribution
            if "dataset_indices_map" in batch:
                for ds_name, indices in batch["dataset_indices_map"].items():
                    print(f"      {ds_name}: {len(indices)}ä¸ªæ ·æœ¬")
            
            # Check images
            if "images" in batch:
                images = batch["images"]
                if isinstance(images, dict):
                    for key, img_tensor in images.items():
                        print(f"      å›¾åƒ({key}): å½¢çŠ¶{img_tensor.shape}")
                else:
                    print(f"      å›¾åƒ: {type(images)}")
            
            # Detailed sample analysis
            batch_size = batch["actions"].shape[0]
            print(f"      æ ·æœ¬è¯¦æƒ…:")
            for sample_idx in range(min(2, batch_size)):  # Check first 2 samples
                # Get dataset name for this sample
                dataset_name = "unknown"
                if "dataset_indices_map" in batch:
                    for ds_name, indices in batch["dataset_indices_map"].items():
                        if sample_idx in indices:
                            dataset_name = ds_name
                            break
                
                actions = batch["actions"][sample_idx]
                print(f"        æ ·æœ¬{sample_idx} ({dataset_name}):")
                print(f"          åŠ¨ä½œ: å½¢çŠ¶{actions.shape}, èŒƒå›´[{actions.min():.3f}, {actions.max():.3f}]")
                
                # Check action padding for RobotWin (should have zeros in last 34 dims)
                if dataset_name == "robotwin_agilex" and actions.shape[-1] == 48:
                    native_actions = actions[..., :14]
                    padded_actions = actions[..., 14:]
                    print(f"          RobotWinåŸç”Ÿ14ç»´: èŒƒå›´[{native_actions.min():.3f}, {native_actions.max():.3f}]")
                    print(f"          å¡«å……34ç»´: èŒƒå›´[{padded_actions.min():.3f}, {padded_actions.max():.3f}] (åº”ä¸º0)")
        
        print("  âœ… å¤šæ•°æ®é›†æ‰¹æ¬¡åŠ è½½æµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"  âŒ å¤šæ•°æ®é›†åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def save_sample_images():
    """Save sample images for visual verification"""
    print("\nğŸ’¾ ä¿å­˜æ ·æœ¬å›¾åƒç”¨äºéªŒè¯...")
    
    try:
        import os
        from PIL import Image as PILImage
        
        # Create save directory
        save_dir = "test/hrdt_data_verification"
        os.makedirs(save_dir, exist_ok=True)
        
        # Test both datasets
        datasets_to_test = [
            ("egodex", "pretrain"),
            ("robotwin_agilex", "finetune")
        ]
        
        for dataset_name, dataset_type in datasets_to_test:
            print(f"  ğŸ“¸ ä¿å­˜{dataset_name}æ ·æœ¬å›¾åƒ...")
            
            try:
                # Create appropriate config
                if dataset_name == "egodex":
                    config = {
                        "common": {
                            "img_history_size": 1,
                            "action_chunk_size": 4,
                            "num_cameras": 1,
                            "state_dim": 48,
                            "action_dim": 48
                        }
                    }
                    num_cameras = 1
                else:  # robotwin_agilex
                    config = {
                        "common": {
                            "img_history_size": 1,
                            "action_chunk_size": 4,
                            "num_cameras": 3,
                            "state_dim": 14,
                            "action_dim": 14
                        }
                    }
                    num_cameras = 3
                
                image_transform = create_simple_image_transform()
                
                # Create dataset
                dataset = VLAConsumerDataset(
                    config=config,
                    image_transform=image_transform,
                    num_cameras=num_cameras,
                    dataset_name=dataset_name,
                    dataset_type=dataset_type,
                    image_aug=False,
                    upsample_rate=3,
                    val=True,
                    use_precomp_lang_embed=True,
                    task_name="open_laptop" if dataset_name == "robotwin_agilex" else None,
                )
                
                # Save a few sample images
                for i in range(min(3, len(dataset))):
                    sample = dataset[i]
                    
                    if "images" in sample:
                        images = sample["images"]
                        
                        if isinstance(images, dict):
                            for key, img_tensor in images.items():
                                # Process tensor to image
                                if img_tensor.dim() == 4:  # [T, C, H, W]
                                    img_to_save = img_tensor[0]  # Take first frame
                                elif img_tensor.dim() == 3:  # [C, H, W]
                                    img_to_save = img_tensor
                                else:
                                    continue
                                
                                # Denormalize
                                def denormalize_image(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
                                    tensor = tensor.clone()
                                    for i, (m, s) in enumerate(zip(mean, std)):
                                        tensor[i] = tensor[i] * s + m
                                    tensor = torch.clamp(tensor, 0, 1)
                                    tensor = tensor.permute(1, 2, 0)  # [H, W, C]
                                    tensor = (tensor * 255).byte().numpy()
                                    return PILImage.fromarray(tensor)
                                
                                pil_img = denormalize_image(img_to_save)
                                img_filename = f"{dataset_name}_sample{i:02d}_{key}.jpg"
                                img_path = os.path.join(save_dir, img_filename)
                                pil_img.save(img_path, quality=95)
                                print(f"    ä¿å­˜: {img_filename}")
                        
                        elif isinstance(images, list):  # Multi-camera
                            for cam_idx, cam_img in enumerate(images):
                                if isinstance(cam_img, dict):
                                    for key, img_tensor in cam_img.items():
                                        # Process similar to above
                                        if img_tensor.dim() == 4:
                                            img_to_save = img_tensor[0]
                                        elif img_tensor.dim() == 3:
                                            img_to_save = img_tensor
                                        else:
                                            continue
                                        
                                        def denormalize_image(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
                                            tensor = tensor.clone()
                                            for i, (m, s) in enumerate(zip(mean, std)):
                                                tensor[i] = tensor[i] * s + m
                                            tensor = torch.clamp(tensor, 0, 1)
                                            tensor = tensor.permute(1, 2, 0)
                                            tensor = (tensor * 255).byte().numpy()
                                            return PILImage.fromarray(tensor)
                                        
                                        pil_img = denormalize_image(img_to_save)
                                        img_filename = f"{dataset_name}_sample{i:02d}_cam{cam_idx}_{key}.jpg"
                                        img_path = os.path.join(save_dir, img_filename)
                                        pil_img.save(img_path, quality=95)
                                        print(f"    ä¿å­˜: {img_filename}")
                                        
                                        if cam_idx >= 2:  # Only save first 3 cameras
                                            break
                
            except Exception as e:
                print(f"    âš ï¸  {dataset_name}å›¾åƒä¿å­˜å¤±è´¥: {e}")
        
        print(f"  âœ… æ ·æœ¬å›¾åƒä¿å­˜å®Œæˆï¼ä¿å­˜è·¯å¾„: {save_dir}/")
        
    except Exception as e:
        print(f"  âŒ å›¾åƒä¿å­˜å¤±è´¥: {e}")

def main():
    """Main test function"""
    print("ğŸš€ H-RDT Data Loading Test")
    print("="*60)
    
    # Set random seeds
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    print(f"Project root: {pyrootutils.find_root(search_from=__file__, indicator='.project-root')}")
    print(f"Working directory: {os.getcwd()}")
    
    # Run tests
    tests_passed = 0
    total_tests = 3
    
    # Test 1: EgoDx data loading
    if test_egodx_data_loading():
        tests_passed += 1
    
    # Test 2: RobotWin data loading
    if test_robotwin_data_loading():
        tests_passed += 1
    
    # Test 3: Multi-dataset loading
    if test_multi_dataset_loading():
        tests_passed += 1
    
    # Bonus: Save sample images
    save_sample_images()
    
    print("\n" + "="*60)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {tests_passed}/{total_tests} é€šè¿‡")
    
    if tests_passed == total_tests:
        print("ğŸ‰ æ‰€æœ‰æ•°æ®åŠ è½½æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… H-RDTæ•°æ®é›†å¯ä»¥æ­£å¸¸è¯»å–å›¾åƒå’Œå…¶ä»–æ•°æ®")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œé…ç½®")
    
    print("\nğŸ“‹ åç»­å»ºè®®:")
    print("  1. æ£€æŸ¥ä¿å­˜çš„æ ·æœ¬å›¾åƒç¡®è®¤è´¨é‡")
    print("  2. è°ƒæ•´æ•°æ®è·¯å¾„é…ç½®åŒ¹é…ä½ çš„ç¯å¢ƒ")
    print("  3. è¿è¡Œå®Œæ•´çš„è®­ç»ƒç®¡é“æµ‹è¯•")

if __name__ == "__main__":
    main()
