"""
Test Action Reconstruction Loss
Tests the action reconstruction loss functionality in EmbodimentAwareLatentMotionTokenizer
"""
import torch
import torch.nn.functional as F
import sys
sys.path.append('/dataset_rc_mm/chenby10@xiaopeng.com/Moto_copy/latent_motion_tokenizer')

from src.models.embodiment_aware_action_encoder import EmbodimentAwareActionEncoder, EmbodimentAwareActionDecoder
from src.models.visual_action_fusion import VisualActionFusion


def test_action_reconstruction_loss():
    """
    æµ‹è¯•action reconstruction lossçš„è®¡ç®—å’Œé›†æˆ
    """
    
    print("ğŸ§ª Testing Action Reconstruction Loss")
    print("=" * 50)
    
    # 1. è®¾ç½®æµ‹è¯•å‚æ•°
    print("\n1ï¸âƒ£ è®¾ç½®æµ‹è¯•å‚æ•°")
    batch_size = 2
    action_chunk_size = 4
    max_action_dim = 48
    hidden_size = 768
    query_num = 8
    num_embodiments = 1
    
    print(f"   ğŸ“Š Batch size: {batch_size}")
    print(f"   ğŸ“Š Action chunk size: {action_chunk_size}")
    print(f"   ğŸ“Š Max action dim: {max_action_dim}")
    print(f"   ğŸ“Š Hidden size: {hidden_size}")
    
    # 2. åˆ›å»ºæµ‹è¯•ç»„ä»¶
    print("\n2ï¸âƒ£ åˆ›å»ºæµ‹è¯•ç»„ä»¶")
    
    # Action encoder
    action_encoder = EmbodimentAwareActionEncoder(
        max_action_dim=max_action_dim,
        hidden_size=hidden_size,
        num_embodiments=num_embodiments
    )
    
    # Action decoder  
    action_decoder = EmbodimentAwareActionDecoder(
        hidden_size=hidden_size,
        max_action_dim=max_action_dim,
        action_chunk_size=action_chunk_size,
        num_embodiments=num_embodiments,
        query_num=query_num
    )
    
    print("   âœ… Action encoder/decoder created")
    
    # 3. å‡†å¤‡æµ‹è¯•æ•°æ®
    print("\n3ï¸âƒ£ å‡†å¤‡æµ‹è¯•æ•°æ®")
    
    # åŸå§‹åŠ¨ä½œåºåˆ—
    original_actions = torch.randn(batch_size, action_chunk_size, max_action_dim)
    states = torch.randn(batch_size, 1, max_action_dim)
    embodiment_ids = torch.zeros(batch_size, dtype=torch.long)
    
    # æ¨¡æ‹Ÿlatent motion tokens (æ¥è‡ªM-Former + fusion)
    latent_motion_tokens = torch.randn(batch_size, query_num, hidden_size)
    
    print(f"   ğŸ“Š Original actions: {original_actions.shape}")
    print(f"   ğŸ“Š States: {states.shape}")
    print(f"   ğŸ“Š Latent motion tokens: {latent_motion_tokens.shape}")
    
    # 4. æµ‹è¯•å®Œæ•´çš„action reconstructionæµç¨‹
    print("\n4ï¸âƒ£ æµ‹è¯•Action Reconstructionæµç¨‹")
    
    with torch.no_grad():
        # Step 1: Encode actions
        action_features = action_encoder.encode_action(original_actions, embodiment_ids)
        state_features = action_encoder.encode_state(states, embodiment_ids)
        
        print(f"   ğŸ”§ Action features: {action_features.shape}")
        print(f"   ğŸ”§ State features: {state_features.shape}")
        
        # Step 2: Decode actions from latent motion tokens
        decoded_actions = action_decoder(latent_motion_tokens, embodiment_ids)
        
        print(f"   ğŸ”§ Decoded actions: {decoded_actions.shape}")
        
        # Step 3: Compute action reconstruction loss
        action_recons_loss = F.mse_loss(decoded_actions, original_actions)
        
        print(f"   ğŸ”§ Action reconstruction loss: {action_recons_loss.item():.6f}")
    
    # 5. æµ‹è¯•ä¸åŒçš„æŸå¤±æƒé‡
    print("\n5ï¸âƒ£ æµ‹è¯•ä¸åŒæŸå¤±æƒé‡çš„å½±å“")
    
    loss_weights = [0.0, 0.5, 1.0, 2.0, 5.0]
    
    for weight in loss_weights:
        # æ¨¡æ‹Ÿå…¶ä»–æŸå¤±ç»„ä»¶
        commit_loss = torch.tensor(0.1)
        recons_loss = torch.tensor(0.5) 
        perceptual_loss = torch.tensor(0.2)
        
        # è®¡ç®—æ€»æŸå¤±
        total_loss = (1.0 * commit_loss + 
                     1.0 * recons_loss + 
                     1.0 * perceptual_loss + 
                     weight * action_recons_loss)
        
        print(f"   ğŸ“Š Weight={weight:.1f}: Total loss={total_loss.item():.4f} " +
              f"(action contribution: {(weight * action_recons_loss).item():.4f})")
    
    # 6. æµ‹è¯•ä¸åŒåŠ¨ä½œç›¸ä¼¼åº¦çš„é‡å»ºæŸå¤±
    print("\n6ï¸âƒ£ æµ‹è¯•ä¸åŒåŠ¨ä½œç›¸ä¼¼åº¦çš„é‡å»ºæŸå¤±")
    
    # ç”Ÿæˆä¸åŒç›¸ä¼¼åº¦çš„è§£ç åŠ¨ä½œ
    similarity_levels = {
        "Perfect reconstruction": original_actions,  # å®Œç¾é‡å»º
        "Small noise": original_actions + 0.1 * torch.randn_like(original_actions),  # å°å™ªå£°
        "Medium noise": original_actions + 0.5 * torch.randn_like(original_actions),  # ä¸­ç­‰å™ªå£°  
        "Large noise": original_actions + 1.0 * torch.randn_like(original_actions),  # å¤§å™ªå£°
        "Random actions": torch.randn_like(original_actions),  # éšæœºåŠ¨ä½œ
    }
    
    for level_name, test_decoded in similarity_levels.items():
        test_loss = F.mse_loss(test_decoded, original_actions)
        print(f"   ğŸ“Š {level_name}: Loss = {test_loss.item():.6f}")
    
    # 7. éªŒè¯æ¢¯åº¦æµ
    print("\n7ï¸âƒ£ éªŒè¯æ¢¯åº¦æµ")
    
    # å¯ç”¨æ¢¯åº¦è®¡ç®—
    original_actions.requires_grad_(True)
    latent_motion_tokens.requires_grad_(True)
    
    # Forward pass
    decoded_actions = action_decoder(latent_motion_tokens, embodiment_ids)
    action_loss = F.mse_loss(decoded_actions, original_actions)
    
    # Backward pass
    action_loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    if latent_motion_tokens.grad is not None:
        grad_norm = torch.norm(latent_motion_tokens.grad).item()
        print(f"   âœ… Gradient flow verified - Latent tokens grad norm: {grad_norm:.6f}")
    else:
        print(f"   âŒ No gradient flow detected")
    
    # 8. æŸå¤±ç»„ä»¶æ€»ç»“
    print(f"\n8ï¸âƒ£ Action Reconstruction Lossæ€»ç»“")
    print("   ğŸ¯ åŠŸèƒ½:")
    print("      â€¢ è¡¡é‡è§£ç åŠ¨ä½œä¸åŸå§‹åŠ¨ä½œçš„ç›¸ä¼¼åº¦")
    print("      â€¢ ä½¿ç”¨MSEæŸå¤±è®¡ç®—é‡å»ºè¯¯å·®")
    print("      â€¢ æ”¯æŒå¯é…ç½®çš„æŸå¤±æƒé‡")
    print("   ğŸ”§ é›†æˆ:")
    print("      â€¢ åœ¨EmbodimentAwareLatentMotionTokenizerä¸­è‡ªåŠ¨è®¡ç®—")
    print("      â€¢ å½“actionsè¾“å…¥ä¸ä¸ºNoneæ—¶å¯ç”¨")
    print("      â€¢ æ·»åŠ åˆ°æ€»æŸå¤±ä¸­: total_loss += action_recons_loss_w * action_recons_loss")
    print("   ğŸ“Š é¢„æœŸæ•ˆæœ:")
    print("      â€¢ ä¿ƒè¿›æ¨¡å‹å­¦ä¹ action-conditionedçš„è§†è§‰è¡¨å¾")
    print("      â€¢ æé«˜åŠ¨ä½œé¢„æµ‹çš„å‡†ç¡®æ€§")
    print("      â€¢ å¢å¼ºå¤šæ¨¡æ€ä¿¡æ¯çš„ä¸€è‡´æ€§")
    
    print(f"\nâœ… Action Reconstruction Lossæµ‹è¯•å®Œæˆ!")
    
    return {
        "action_recons_loss": action_recons_loss.item(),
        "original_shape": original_actions.shape,
        "decoded_shape": decoded_actions.shape,
        "gradient_flow": latent_motion_tokens.grad is not None
    }


def test_loss_integration():
    """
    æµ‹è¯•æŸå¤±åœ¨å®Œæ•´æ¨¡å‹ä¸­çš„é›†æˆ (ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸ä¾èµ–å®Œæ•´æ¨¡å‹åŠ è½½)
    """
    
    print("\nğŸ”— Testing Loss Integration")
    print("=" * 30)
    
    # æ¨¡æ‹Ÿå®Œæ•´æ¨¡å‹çš„æŸå¤±è®¡ç®—é€»è¾‘
    batch_size = 2
    
    # æ¨¡æ‹Ÿå„ç§æŸå¤±ç»„ä»¶
    commit_loss = torch.tensor(0.15)
    recons_loss = torch.tensor(0.45)  
    perceptual_loss = torch.tensor(0.25)
    action_recons_loss = torch.tensor(0.35)
    
    # æŸå¤±æƒé‡ (æ¥è‡ªé…ç½®)
    commit_loss_w = 1.0
    recon_loss_w = 1.0
    perceptual_loss_w = 1.0
    action_recons_loss_w = 1.0
    
    print(f"   ğŸ“Š Individual losses:")
    print(f"      â€¢ Commit loss: {commit_loss.item():.4f}")
    print(f"      â€¢ Recons loss: {recons_loss.item():.4f}")
    print(f"      â€¢ Perceptual loss: {perceptual_loss.item():.4f}")
    print(f"      â€¢ Action recons loss: {action_recons_loss.item():.4f}")
    
    # è®¡ç®—æ€»æŸå¤±
    total_loss = (commit_loss_w * commit_loss + 
                  recon_loss_w * recons_loss + 
                  perceptual_loss_w * perceptual_loss +
                  action_recons_loss_w * action_recons_loss)
    
    print(f"   ğŸ¯ Total loss: {total_loss.item():.4f}")
    
    # åˆ†æå„ç»„ä»¶è´¡çŒ®
    contributions = {
        "Commit": (commit_loss_w * commit_loss / total_loss * 100).item(),
        "Recons": (recon_loss_w * recons_loss / total_loss * 100).item(),
        "Perceptual": (perceptual_loss_w * perceptual_loss / total_loss * 100).item(),
        "Action": (action_recons_loss_w * action_recons_loss / total_loss * 100).item(),
    }
    
    print(f"   ğŸ“Š Loss contributions:")
    for name, contrib in contributions.items():
        print(f"      â€¢ {name}: {contrib:.1f}%")
    
    print(f"   âœ… Loss integration verified!")


if __name__ == "__main__":
    # æµ‹è¯•action reconstruction loss
    results = test_action_reconstruction_loss()
    
    # æµ‹è¯•æŸå¤±é›†æˆ
    test_loss_integration()
