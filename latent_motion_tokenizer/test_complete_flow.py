"""
Test Complete Action-Vision Data Flow
Tests the full pipeline: [action & vision] -> [action feature & vision feature] -> [feature fusion] -> [visual & action reconstruction]
"""
import torch
import sys
sys.path.append('/dataset_rc_mm/chenby10@xiaopeng.com/Moto_copy/latent_motion_tokenizer')

from src.models.embodiment_aware_action_encoder import EmbodimentAwareActionEncoder, EmbodimentAwareActionDecoder
from src.models.visual_action_fusion import VisualActionFusion
from src.models.a_former import AFormer
from transformers import ViTConfig


def test_complete_data_flow():
    """
    æµ‹è¯•å®Œæ•´çš„action-visionæ•°æ®æµ
    """
    
    print("ğŸš€ Testing Complete Action-Vision Data Flow")
    print("=" * 60)
    
    # 1. è®¾ç½®æµ‹è¯•å‚æ•°
    print("\n1ï¸âƒ£ è®¾ç½®æµ‹è¯•å‚æ•°")
    batch_size = 2
    action_chunk_size = 4
    max_action_dim = 48
    hidden_size = 768
    query_num = 8
    num_embodiments = 1
    
    print(f"   ğŸ“Š Batch size: {batch_size}")
    print(f"   ğŸ“Š Action chunk size: {action_chunk_size}")
    print(f"   ğŸ“Š Max action dim: {max_action_dim}")
    print(f"   ğŸ“Š Hidden size: {hidden_size}")
    print(f"   ğŸ“Š Query num: {query_num}")
    
    # 2. åˆ›å»ºæ‰€æœ‰ç»„ä»¶
    print("\n2ï¸âƒ£ åˆ›å»ºæ•°æ®æµç»„ä»¶")
    
    # Action encoder/decoder
    action_encoder = EmbodimentAwareActionEncoder(
        max_action_dim=max_action_dim,
        hidden_size=hidden_size,
        num_embodiments=num_embodiments
    )
    
    action_decoder = EmbodimentAwareActionDecoder(
        hidden_size=hidden_size,
        max_action_dim=max_action_dim,
        action_chunk_size=action_chunk_size,
        num_embodiments=num_embodiments,
        query_num=query_num
    )
    
    # A-Former
    a_former_config = ViTConfig(
        hidden_size=hidden_size,
        num_hidden_layers=4,
        num_attention_heads=12,
        intermediate_size=3072,
        query_num=query_num,
        action_chunk_size=action_chunk_size,
        model_type="vit"
    )
    a_former = AFormer(a_former_config)
    
    # Fusion module
    fusion_module = VisualActionFusion(
        hidden_size=hidden_size,
        num_heads=8,
        query_num=query_num,
        dropout=0.1
    )
    
    print("   âœ… All components created successfully")
    
    # 3. å‡†å¤‡æµ‹è¯•æ•°æ®
    print("\n3ï¸âƒ£ å‡†å¤‡æµ‹è¯•æ•°æ®")
    
    # åŸå§‹è¾“å…¥
    actions = torch.randn(batch_size, action_chunk_size, max_action_dim)
    states = torch.randn(batch_size, 1, max_action_dim)
    embodiment_ids = torch.zeros(batch_size, dtype=torch.long)
    
    # æ¨¡æ‹Ÿè§†è§‰tokens (æ¥è‡ªM-Former)
    visual_tokens = torch.randn(batch_size, query_num, hidden_size)
    
    print(f"   ğŸ“Š Actions: {actions.shape}")
    print(f"   ğŸ“Š States: {states.shape}")
    print(f"   ğŸ“Š Visual tokens: {visual_tokens.shape}")
    
    # 4. æµ‹è¯•å®Œæ•´æ•°æ®æµ
    print("\n4ï¸âƒ£ æ‰§è¡Œå®Œæ•´æ•°æ®æµ")
    
    with torch.no_grad():
        
        # Step 1: Action & State Encoding
        print("   ğŸ”„ Step 1: Action & State Encoding")
        action_features = action_encoder.encode_action(actions, embodiment_ids)
        state_features = action_encoder.encode_state(states, embodiment_ids)
        
        print(f"      â€¢ Actions {actions.shape} -> Action features {action_features.shape}")
        print(f"      â€¢ States {states.shape} -> State features {state_features.shape}")
        
        # Step 2: A-Former Tokenization
        print("   ğŸ”„ Step 2: A-Former Tokenization")
        a_former_output = a_former(state_features, action_features)  # ä¿®æ­£å‚æ•°é¡ºåº
        action_tokens = a_former_output.last_hidden_state
        
        print(f"      â€¢ Action features {action_features.shape} + State features {state_features.shape}")
        print(f"        -> Action tokens {action_tokens.shape}")
        
        # Step 3: Visual-Action Fusion
        print("   ğŸ”„ Step 3: Visual-Action Fusion")
        pv = torch.ones(batch_size, dtype=torch.long)  # Visual present
        pa = torch.ones(batch_size, dtype=torch.long)  # Action present
        
        fused_tokens = fusion_module(
            visual_tokens=visual_tokens,
            action_tokens=action_tokens,
            pv=pv,
            pa=pa
        )
        
        print(f"      â€¢ Visual tokens {visual_tokens.shape} + Action tokens {action_tokens.shape}")
        print(f"        -> Fused tokens {fused_tokens.shape}")
        
        # Step 4: Action Reconstruction
        print("   ğŸ”„ Step 4: Action Reconstruction")
        decoded_actions = action_decoder(fused_tokens, embodiment_ids)
        
        print(f"      â€¢ Fused tokens {fused_tokens.shape} -> Decoded actions {decoded_actions.shape}")
        
        # Step 5: Loss Computation
        print("   ğŸ”„ Step 5: Loss Computation")
        action_recons_loss = torch.nn.functional.mse_loss(decoded_actions, actions)
        
        print(f"      â€¢ Action reconstruction loss: {action_recons_loss.item():.6f}")
    
    # 5. éªŒè¯æ•°æ®æµå®Œæ•´æ€§
    print("\n5ï¸âƒ£ éªŒè¯æ•°æ®æµå®Œæ•´æ€§")
    
    # æ£€æŸ¥ç»´åº¦ä¸€è‡´æ€§
    assert action_features.shape == (batch_size, action_chunk_size, hidden_size), f"Action features shape mismatch: {action_features.shape}"
    assert state_features.shape == (batch_size, 1, hidden_size), f"State features shape mismatch: {state_features.shape}"
    assert action_tokens.shape == (batch_size, query_num, hidden_size), f"Action tokens shape mismatch: {action_tokens.shape}"
    assert fused_tokens.shape == (batch_size, query_num, hidden_size), f"Fused tokens shape mismatch: {fused_tokens.shape}"
    assert decoded_actions.shape == actions.shape, f"Decoded actions shape mismatch: {decoded_actions.shape} vs {actions.shape}"
    
    print("   âœ… All dimensions consistent")
    
    # æ£€æŸ¥æ•°å€¼èŒƒå›´
    print(f"   ğŸ“Š Value ranges:")
    print(f"      â€¢ Action features: [{action_features.min():.3f}, {action_features.max():.3f}]")
    print(f"      â€¢ Action tokens: [{action_tokens.min():.3f}, {action_tokens.max():.3f}]")
    print(f"      â€¢ Fused tokens: [{fused_tokens.min():.3f}, {fused_tokens.max():.3f}]")
    print(f"      â€¢ Decoded actions: [{decoded_actions.min():.3f}, {decoded_actions.max():.3f}]")
    
    # 6. æµ‹è¯•ä¸åŒè¾“å…¥ç»„åˆ
    print("\n6ï¸âƒ£ æµ‹è¯•ä¸åŒè¾“å…¥ç»„åˆ")
    
    test_cases = [
        {"name": "Action + State", "actions": actions, "states": states},
        {"name": "Action only", "actions": actions, "states": None},
        {"name": "State only", "actions": None, "states": states},
    ]
    
    for case in test_cases:
        print(f"   ğŸ§ª Testing: {case['name']}")
        
        with torch.no_grad():
            # Action encoding
            action_feats = None
            state_feats = None
            
            if case['actions'] is not None:
                action_feats = action_encoder.encode_action(case['actions'], embodiment_ids)
            if case['states'] is not None:
                state_feats = action_encoder.encode_state(case['states'], embodiment_ids)
            
            # A-Former with fallback handling
            if action_feats is not None and state_feats is not None:
                action_toks = a_former(state_feats, action_feats).last_hidden_state  # ä¿®æ­£å‚æ•°é¡ºåº
            elif action_feats is not None:
                zero_states = torch.zeros(batch_size, 1, hidden_size)
                action_toks = a_former(zero_states, action_feats).last_hidden_state  # ä¿®æ­£å‚æ•°é¡ºåº
            elif state_feats is not None:
                zero_actions = torch.zeros(batch_size, action_chunk_size, hidden_size)
                action_toks = a_former(state_feats, zero_actions).last_hidden_state  # ä¿®æ­£å‚æ•°é¡ºåº
            else:
                action_toks = None
            
            # Fusion
            pa_flag = torch.ones(batch_size, dtype=torch.long) if action_toks is not None else torch.zeros(batch_size, dtype=torch.long)
            fused = fusion_module(visual_tokens, action_toks, pv, pa_flag)
            
            print(f"      âœ… {case['name']}: Fusion output {fused.shape}")
    
    # 7. æ•°æ®æµæ€»ç»“
    print(f"\n7ï¸âƒ£ å®Œæ•´æ•°æ®æµæ€»ç»“")
    print("   ğŸ¯ Input:")
    print(f"      â€¢ Actions: (B, chunk_size, action_dim) = {actions.shape}")
    print(f"      â€¢ States: (B, 1, state_dim) = {states.shape}")
    print(f"      â€¢ Visual tokens: (B, query_num, hidden_size) = {visual_tokens.shape}")
    
    print("   ğŸ”„ Processing:")
    print(f"      â€¢ Action Encoder: actions -> action_features {action_features.shape}")
    print(f"      â€¢ State Encoder: states -> state_features {state_features.shape}")
    print(f"      â€¢ A-Former: action_features + state_features -> action_tokens {action_tokens.shape}")
    print(f"      â€¢ Fusion: visual_tokens + action_tokens -> fused_tokens {fused_tokens.shape}")
    print(f"      â€¢ Action Decoder: fused_tokens -> decoded_actions {decoded_actions.shape}")
    
    print("   ğŸ¯ Output:")
    print(f"      â€¢ Fused multimodal tokens: {fused_tokens.shape}")
    print(f"      â€¢ Reconstructed actions: {decoded_actions.shape}")
    print(f"      â€¢ Action reconstruction loss: {action_recons_loss.item():.6f}")
    
    print(f"\nâœ… Complete Action-Vision Data Flow Test Passed!")
    
    return {
        "action_features": action_features,
        "state_features": state_features,
        "action_tokens": action_tokens,
        "fused_tokens": fused_tokens,
        "decoded_actions": decoded_actions,
        "action_recons_loss": action_recons_loss.item()
    }


def test_integration_with_model():
    """
    æµ‹è¯•ä¸EmbodimentAwareLatentMotionTokenizerçš„é›†æˆ (ç®€åŒ–ç‰ˆæœ¬)
    """
    
    print("\nğŸ”— Testing Integration with Main Model")
    print("=" * 40)
    
    # æ¨¡æ‹Ÿå®Œæ•´æ¨¡å‹çš„forward passé€»è¾‘
    print("   ğŸ“‹ Simulating complete model forward pass:")
    print("   1. Visual processing: cond_images + target_images -> M-Former -> visual_tokens")
    print("   2. Action processing: actions + states -> Action Encoder -> action_features")
    print("   3. Action tokenization: action_features -> A-Former -> action_tokens")
    print("   4. Multimodal fusion: visual_tokens + action_tokens -> fused_tokens")
    print("   5. Vector quantization: fused_tokens -> VQ -> quantized_tokens")
    print("   6. Reconstruction: quantized_tokens -> Visual Decoder + Action Decoder")
    print("   7. Loss computation: visual_loss + action_recons_loss")
    
    print("   âœ… Integration flow verified conceptually")
    print("   ğŸ“ Ready for full model testing with actual image inputs")


if __name__ == "__main__":
    # æµ‹è¯•å®Œæ•´æ•°æ®æµ
    results = test_complete_data_flow()
    
    # æµ‹è¯•æ¨¡å‹é›†æˆ
    test_integration_with_model()
    
    print(f"\nğŸ‰ All tests completed successfully!")
    print(f"   Action reconstruction loss: {results['action_recons_loss']:.6f}")
    print(f"   Data flow integrity: âœ… PASSED")
